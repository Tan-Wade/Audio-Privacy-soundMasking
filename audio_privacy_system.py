#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ - åŸºäºå£°éŸ³æ©è”½æŠ€æœ¯çš„æ™ºèƒ½æ‰‹æœºéŸ³é¢‘éšç§ä¿æŠ¤
Audio Privacy Protection System using Sound Masking Techniques

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¯¹å¹²å‡€è¯­éŸ³æ–½åŠ æ©è”½å™ªå£°ï¼ˆç±»ä¼¼"åŠ å¯†"ï¼‰
2. ç”Ÿæˆæ··åˆä¿¡å·ï¼ˆæ¨¡æ‹Ÿè¢«ç›‘å¬æ–¹å½•åˆ°çš„å£°éŸ³ï¼‰
3. æˆæƒæ–¹ä½¿ç”¨å·²çŸ¥å‚æ•°è¿›è¡Œåå‘æ¢å¤
4. éæˆæƒæ–¹åªèƒ½å¬åˆ°å«æ··çš„æ··åˆä¿¡å·

ä½œè€…ï¼šåŸºäºè®ºæ–‡ "Exploiting Sound Masking for Audio Privacy in Smartphones"
"""

import os
import numpy as np
from pathlib import Path
import json
from typing import Tuple, List, Optional
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥éŸ³é¢‘è´¨é‡è¯„ä¼°æ¨¡å—
try:
    from audio_metrics import AudioMetrics
    HAVE_METRICS = True
except ImportError:
    HAVE_METRICS = False

# éŸ³é¢‘å¤„ç†ä¾èµ–
try:
    import soundfile as sf
    HAVE_SF = True
except ImportError:
    try:
        from scipy.io import wavfile
        HAVE_SF = False
    except ImportError:
        print("è­¦å‘Šï¼šéœ€è¦å®‰è£… soundfile æˆ– scipy æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶")
        HAVE_SF = None

class AudioPrivacySystem:
    """éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, sample_rate: int = 16000, target_snr_db: float = 0.0):
        """
        åˆå§‹åŒ–éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ
        
        Args:
            sample_rate: é‡‡æ ·ç‡ï¼Œé»˜è®¤16kHzï¼ˆé€‚åˆè¯­éŸ³ï¼‰
            target_snr_db: ç›®æ ‡ä¿¡å™ªæ¯”ï¼Œé»˜è®¤0dBï¼ˆæ©è”½æ•ˆæœè¾ƒå¼ºï¼‰
        """
        self.sr = sample_rate
        self.target_snr_db = target_snr_db
        self.output_dir = Path("./audio_outputs")
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–éŸ³é¢‘è´¨é‡è¯„ä¼°å™¨
        self.metrics_calc = AudioMetrics(sample_rate) if HAVE_METRICS else None
        
        # è¯­éŸ³ç‰¹å¾å‚æ•°ï¼ˆé’ˆå¯¹ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–ï¼‰
        self.voice_params = {
            'f0_range': (80, 300),      # åŸºé¢‘èŒƒå›´
            'formants': [800, 1200, 2500, 3500],  # å…±æŒ¯å³°é¢‘ç‡
            'speech_band': (200, 4000), # è¯­éŸ³é¢‘å¸¦
            'syllable_rate': (2, 5),    # éŸ³èŠ‚é€Ÿç‡ (Hz)
        }
        
    def load_audio(self, file_path: str, force_mono: bool = True) -> Tuple[np.ndarray, int]:
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        if HAVE_SF:
            data, sr = sf.read(file_path, always_2d=False)
        else:
            sr, data = wavfile.read(file_path)
            # å½’ä¸€åŒ–åˆ°float32
            if data.dtype == np.int16:
                data = data.astype(np.float32) / 32768.0
            else:
                data = data.astype(np.float32) / np.max(1e-9 + np.abs(data))
        
        # è½¬æ¢ä¸ºå•å£°é“
        if data.ndim == 2:
            data = np.mean(data, axis=1)
        
        # é‡é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sr != self.sr:
            data = self._resample(data, sr, self.sr)
            sr = self.sr
            
        return data.astype(np.float32), sr
    
    def save_audio(self, file_path: str, data: np.ndarray, sr: int = None):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        if sr is None:
            sr = self.sr
            
        data = np.asarray(data, dtype=np.float32)
        data = np.clip(data, -1.0, 1.0)
        
        if HAVE_SF:
            sf.write(file_path, data, sr, subtype="PCM_16")
        else:
            from scipy.io.wavfile import write as wav_write
            wav_write(file_path, sr, (data * 32767).astype(np.int16))
    
    def _resample(self, data: np.ndarray, old_sr: int, new_sr: int) -> np.ndarray:
        """ç®€å•é‡é‡‡æ ·ï¼ˆçº¿æ€§æ’å€¼ï¼‰"""
        if old_sr == new_sr:
            return data
            
        ratio = new_sr / old_sr
        new_len = int(len(data) * ratio)
        x_old = np.linspace(0, 1, num=len(data), endpoint=False)
        x_new = np.linspace(0, 1, num=new_len, endpoint=False)
        return np.interp(x_new, x_old, data).astype(np.float32)
    
    def generate_voice_like_mask(self, length: int, sr: int = None) -> np.ndarray:
        """
        ç”Ÿæˆç±»è¯­éŸ³æ©è”½å™ªå£°
        åŸºäºè®ºæ–‡å»ºè®®ï¼Œä½¿ç”¨è¯­éŸ³æ ·å¼çš„å™ªå£°æ¯”ç™½å™ªå£°æ›´æœ‰æ•ˆ
        """
        if sr is None:
            sr = self.sr
            
        # 1. ç”Ÿæˆç™½å™ªå£°
        white_noise = np.random.randn(length).astype(np.float32)
        
        # 2. å¸¦é€šæ»¤æ³¢åˆ°è¯­éŸ³é¢‘å¸¦
        filtered_noise = self._bandpass_filter(white_noise, sr)
        
        # 3. æ·»åŠ éŸ³èŠ‚å¼è°ƒåˆ¶ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„èƒ½é‡å˜åŒ–ï¼‰
        syllable_modulation = self._generate_syllable_modulation(length, sr)
        
        # 4. ç»„åˆç”Ÿæˆç±»è¯­éŸ³å™ªå£°
        voice_like = filtered_noise * syllable_modulation
        
        # 5. å½’ä¸€åŒ–
        voice_like = voice_like / (np.max(np.abs(voice_like)) + 1e-9)
        
        return voice_like.astype(np.float32)
    
    def _bandpass_filter(self, signal: np.ndarray, sr: int) -> np.ndarray:
        """ç®€å•çš„å¸¦é€šæ»¤æ³¢å™¨ï¼ˆçª—å£åŒ–sincï¼‰"""
        low_freq, high_freq = self.voice_params['speech_band']
        
        # è®¾è®¡FIRæ»¤æ³¢å™¨
        numtaps = 513
        nyq = sr / 2.0
        f1 = low_freq / nyq
        f2 = high_freq / nyq
        
        # çª—å£åŒ–sincå¸¦é€šæ»¤æ³¢å™¨
        n = np.arange(numtaps) - (numtaps - 1) / 2.0
        
        def sinc(x):
            return np.sinc(x / np.pi)
            
        h = (2 * f2 * sinc(2 * np.pi * f2 * n) - 2 * f1 * sinc(2 * np.pi * f1 * n))
        
        # Hannçª—
        window = 0.5 * (1 - np.cos(2 * np.pi * np.arange(numtaps) / (numtaps - 1)))
        h = h * window
        
        # å½’ä¸€åŒ–
        h = h / np.sum(h)
        
        # åº”ç”¨æ»¤æ³¢å™¨
        filtered = np.convolve(signal, h, mode='same')
        return filtered.astype(np.float32)
    
    def _generate_syllable_modulation(self, length: int, sr: int) -> np.ndarray:
        """ç”ŸæˆéŸ³èŠ‚å¼è°ƒåˆ¶ä¿¡å·"""
        # éšæœºéŸ³èŠ‚é€Ÿç‡
        syllable_rate = np.random.uniform(*self.voice_params['syllable_rate'])
        
        # ç”ŸæˆéšæœºåŒ…ç»œ
        env_length = max(1, length // 400)  # ç²—ç²’åº¦åŒ…ç»œ
        envelope = np.abs(np.random.randn(env_length)).astype(np.float32)
        
        # ä¸Šé‡‡æ ·åˆ°ä¿¡å·é•¿åº¦
        t_env = np.linspace(0, env_length - 1, num=length)
        envelope_up = np.interp(t_env, np.arange(env_length), envelope)
        
        # å¹³æ»‘åŒ…ç»œï¼ˆæ¨¡æ‹ŸéŸ³èŠ‚è¾¹ç•Œï¼‰
        smooth_kernel = np.ones(51, dtype=np.float32) / 51.0
        envelope_smooth = np.convolve(envelope_up, smooth_kernel, mode='same')
        envelope_smooth = envelope_smooth / (np.max(np.abs(envelope_smooth)) + 1e-9)
        
        # æ·»åŠ éŸ³èŠ‚å¼è°ƒåˆ¶
        t = np.linspace(0, length / sr, length, endpoint=False)
        syllable_mod = 0.3 + 0.7 * (0.5 + 0.5 * np.sin(2 * np.pi * syllable_rate * t))
        
        return envelope_smooth * syllable_mod
    
    def mix_signals(self, clean: np.ndarray, mask: np.ndarray, target_snr_db: float = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        å°†å¹²å‡€ä¿¡å·å’Œæ©è”½ä¿¡å·æŒ‰æŒ‡å®šä¿¡å™ªæ¯”æ··åˆ
        
        Args:
            clean: å¹²å‡€è¯­éŸ³ä¿¡å·
            mask: æ©è”½å™ªå£°ä¿¡å·
            target_snr_db: ç›®æ ‡ä¿¡å™ªæ¯”ï¼ˆdBï¼‰
            
        Returns:
            mixed: æ··åˆåçš„ä¿¡å·
            scaled_mask: ç¼©æ”¾åçš„æ©è”½ä¿¡å·
        """
        if target_snr_db is None:
            target_snr_db = self.target_snr_db
            
        # è®¡ç®—RMS
        clean_rms = np.sqrt(np.mean(clean ** 2) + 1e-12)
        mask_rms = np.sqrt(np.mean(mask ** 2) + 1e-12)
        
        if mask_rms < 1e-12:
            return clean.copy(), mask.copy()
        
        # è®¡ç®—æ‰€éœ€çš„æ©è”½ä¿¡å·å¹…åº¦
        desired_mask_rms = clean_rms / (10.0 ** (target_snr_db / 20.0))
        scale_factor = desired_mask_rms / mask_rms
        
        # ç¼©æ”¾æ©è”½ä¿¡å·
        scaled_mask = mask * scale_factor
        
        # æ··åˆä¿¡å·
        mixed = clean + scaled_mask
        
        return mixed, scaled_mask
    
    def lms_recovery(self, mixed: np.ndarray, mask_ref: np.ndarray, 
                     mu: float = 0.01, filter_order: int = 128) -> Tuple[np.ndarray, np.ndarray]:
        """
        LMSè‡ªé€‚åº”æ»¤æ³¢å™¨è¿›è¡Œæˆæƒæ¢å¤
        
        Args:
            mixed: è§‚æµ‹ä¿¡å· (clean + mask)
            mask_ref: å‚è€ƒæ©è”½ä¿¡å·ï¼ˆæˆæƒæ–¹å·²çŸ¥ï¼‰
            mu: å­¦ä¹ ç‡
            filter_order: æ»¤æ³¢å™¨é˜¶æ•°
            
        Returns:
            recovered: æ¢å¤çš„å¹²å‡€ä¿¡å·
            filter_taps: æ»¤æ³¢å™¨ç³»æ•°
        """
        n = len(mixed)
        w = np.zeros(filter_order, dtype=np.float32)
        x_buffer = np.zeros(filter_order, dtype=np.float32)
        recovered = np.zeros(n, dtype=np.float32)
        
        for i in range(n):
            # æ›´æ–°è¾“å…¥ç¼“å†²åŒº
            x_buffer[1:] = x_buffer[:-1]
            x_buffer[0] = mask_ref[i] if i < len(mask_ref) else 0.0
            
            # è®¡ç®—æ»¤æ³¢å™¨è¾“å‡º
            y = np.dot(w, x_buffer)
            
            # è®¡ç®—è¯¯å·®ä¿¡å·ï¼ˆè¿™åº”è¯¥æ˜¯å¹²å‡€è¯­éŸ³çš„ä¼°è®¡ï¼‰
            error = mixed[i] - y
            recovered[i] = error
            
            # LMSæ›´æ–°
            w += 2 * mu * error * x_buffer
        
        return recovered, w
    
    def calculate_snr(self, signal: np.ndarray, noise: np.ndarray) -> float:
        """è®¡ç®—ä¿¡å™ªæ¯”ï¼ˆdBï¼‰"""
        signal_power = np.mean(signal ** 2) + 1e-12
        noise_power = np.mean(noise ** 2) + 1e-12
        
        if noise_power < 1e-12:
            return float('inf')  # æ— å™ªå£°æƒ…å†µ
        
        snr = 10.0 * np.log10(signal_power / noise_power)
        
        # å¤„ç†NaNå’Œæ— ç©·å¤§å€¼
        if np.isnan(snr) or np.isinf(snr):
            return 0.0
            
        return snr
    
    def process_audio_pair(self, clean_path: str, output_prefix: str = "") -> dict:
        """
        å¤„ç†éŸ³é¢‘å¯¹ï¼šå¹²å‡€è¯­éŸ³ -> æ©è”½ -> æ··åˆ -> æ¢å¤
        
        Args:
            clean_path: å¹²å‡€è¯­éŸ³æ–‡ä»¶è·¯å¾„
            output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        # 1. åŠ è½½å¹²å‡€è¯­éŸ³
        clean, _ = self.load_audio(clean_path)
        print(f"åŠ è½½å¹²å‡€è¯­éŸ³: {clean_path}, é•¿åº¦: {len(clean)/self.sr:.2f}ç§’")
        
        # 2. ç”Ÿæˆæ©è”½å™ªå£°
        mask = self.generate_voice_like_mask(len(clean))
        print("ç”Ÿæˆç±»è¯­éŸ³æ©è”½å™ªå£°")
        
        # 3. æ··åˆä¿¡å·
        mixed, scaled_mask = self.mix_signals(clean, mask)
        print(f"æ··åˆä¿¡å·ï¼Œç›®æ ‡SNR: {self.target_snr_db:.1f}dB")
        
        # 4. æˆæƒæ¢å¤
        recovered, filter_taps = self.lms_recovery(mixed, scaled_mask)
        print("æ‰§è¡ŒLMSæˆæƒæ¢å¤")
        
        # 5. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        snr_input = self.calculate_snr(clean, scaled_mask)
        snr_after = self.calculate_snr(clean, recovered - clean)
        improvement = snr_after - snr_input
        
        print(f"è¾“å…¥SNR: {snr_input:.2f}dB")
        print(f"æ¢å¤åSNR: {snr_after:.2f}dB")
        print(f"SNRæ”¹å–„: {improvement:.2f}dB")
        
        # 6. è¯¦ç»†è´¨é‡è¯„ä¼°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.metrics_calc:
            print("\nğŸ“Š è¯¦ç»†è´¨é‡è¯„ä¼°:")
            mixed_metrics = self.metrics_calc.calculate_all_metrics(clean, mixed)
            recovery_metrics = self.metrics_calc.evaluate_recovery_quality(clean, recovered)
            
            print(f"æ··åˆä¿¡å·è´¨é‡:")
            print(f"  - SNR: {mixed_metrics['snr_db']:.2f} dB")
            print(f"  - STOI: {mixed_metrics['stoi']:.3f}")
            
            print(f"æ¢å¤ä¿¡å·è´¨é‡:")
            print(f"  - SNR: {recovery_metrics['snr_db']:.2f} dB")
            print(f"  - STOI: {recovery_metrics['stoi']:.3f}")
            print(f"  - ä¿¡å·ä¿æŒåº¦: {recovery_metrics['signal_preservation']:.3f}")
        
        # 7. ä¿å­˜æ–‡ä»¶
        if not output_prefix:
            output_prefix = Path(clean_path).stem
            
        clean_out = self.output_dir / f"{output_prefix}_clean.wav"
        mask_out = self.output_dir / f"{output_prefix}_mask.wav"
        mixed_out = self.output_dir / f"{output_prefix}_mixed.wav"
        recovered_out = self.output_dir / f"{output_prefix}_recovered.wav"
        
        self.save_audio(clean_out, clean)
        self.save_audio(mask_out, scaled_mask)
        self.save_audio(mixed_out, mixed)
        self.save_audio(recovered_out, recovered)
        
        # 8. è¿”å›ç»“æœ
        results = {
            'input_file': clean_path,
            'output_files': {
                'clean': str(clean_out),
                'mask': str(mask_out),
                'mixed': str(mixed_out),
                'recovered': str(recovered_out)
            },
            'metrics': {
                'input_snr_db': snr_input,
                'output_snr_db': snr_after,
                'improvement_db': improvement,
                'signal_length_sec': len(clean) / self.sr
            },
            'parameters': {
                'sample_rate': self.sr,
                'target_snr_db': self.target_snr_db,
                'filter_order': 128,
                'learning_rate': 0.01
            }
        }
        
        return results
    
    def batch_process(self, clean_files: List[str], output_prefixes: List[str] = None) -> List[dict]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶"""
        if output_prefixes is None:
            output_prefixes = [Path(f).stem for f in clean_files]
            
        results = []
        for clean_file, prefix in zip(clean_files, output_prefixes):
            try:
                result = self.process_audio_pair(clean_file, prefix)
                results.append(result)
                print(f"âœ“ å®Œæˆå¤„ç†: {prefix}")
            except Exception as e:
                print(f"âœ— å¤„ç†å¤±è´¥: {prefix}, é”™è¯¯: {e}")
                results.append(None)
                
        return results
    


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºéŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ"""
    print("=== éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿæ¼”ç¤º ===")
    print("åŸºäºå£°éŸ³æ©è”½æŠ€æœ¯çš„æ™ºèƒ½æ‰‹æœºéŸ³é¢‘éšç§ä¿æŠ¤")
    print()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = AudioPrivacySystem(sample_rate=16000, target_snr_db=0.0)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰éŸ³é¢‘æ–‡ä»¶
    existing_files = []
    for filename in ['01_clean.wav', '02_mask.wav', '03_mixed.wav', '04_recovered.wav']:
        if os.path.exists(filename):
            existing_files.append(filename)
    
    if existing_files:
        print(f"å‘ç°ç°æœ‰éŸ³é¢‘æ–‡ä»¶: {existing_files}")
        print("ä½¿ç”¨ç°æœ‰æ–‡ä»¶è¿›è¡Œæ¼”ç¤º...")
        
        # ä½¿ç”¨ç°æœ‰çš„cleanæ–‡ä»¶
        if '01_clean.wav' in existing_files:
            result = system.process_audio_pair('01_clean.wav', 'demo')
            print(f"\nå¤„ç†ç»“æœ:")
            print(f"- è¾“å…¥SNR: {result['metrics']['input_snr_db']:.2f}dB")
            print(f"- æ¢å¤åSNR: {result['metrics']['output_snr_db']:.2f}dB")
            print(f"- SNRæ”¹å–„: {result['metrics']['improvement_db']:.2f}dB")
            print(f"\nè¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {system.output_dir}")
    else:
        print("æœªå‘ç°ç°æœ‰éŸ³é¢‘æ–‡ä»¶ã€‚")
        print("è¯·å°†ä½ çš„8ä½æ•°å­—å½•éŸ³æ–‡ä»¶å‘½åä¸º '01_clean.wav' å¹¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œç„¶åé‡æ–°è¿è¡Œã€‚")
        print("æˆ–è€…è¿è¡Œ 'python demo.py' è¿›è¡Œå¿«é€Ÿæ¼”ç¤ºã€‚")
    
    print("\n=== ç³»ç»Ÿè¯´æ˜ ===")
    print("1. å¹²å‡€è¯­éŸ³: åŸå§‹è¯­éŸ³ä¿¡å·")
    print("2. æ©è”½å™ªå£°: ç±»è¯­éŸ³æ ·å¼çš„å™ªå£°ä¿¡å·")
    print("3. æ··åˆä¿¡å·: æ¨¡æ‹Ÿè¢«ç›‘å¬æ–¹å½•åˆ°çš„å£°éŸ³ï¼ˆå«æ··ä¸æ¸…ï¼‰")
    print("4. æ¢å¤ä¿¡å·: æˆæƒæ–¹ä½¿ç”¨å·²çŸ¥å‚æ•°æ¢å¤çš„æ¸…æ™°è¯­éŸ³")
    print("\næ ¸å¿ƒåŸç†ï¼šåªæœ‰æˆæƒæ–¹çŸ¥é“æ©è”½å™ªå£°çš„ç²¾ç¡®å‚æ•°ï¼Œå¯ä»¥åå‘æ¢å¤åŸå§‹è¯­éŸ³")


if __name__ == "__main__":
    main()
