#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Audio Privacy Protection System using Sound Masking Techniques
éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ - åŸºäºå£°éŸ³æ©è”½æŠ€æœ¯çš„æ™ºèƒ½æ‰‹æœºéŸ³é¢‘éšç§ä¿æŠ¤

Core Functions:
1. Apply masking noise to clean speech (similar to "encryption")
2. Generate mixed signal (simulate what eavesdroppers would record)
3. Authorized parties use known parameters for reverse recovery
4. Unauthorized parties can only hear mixed signals

Author: Based on paper "Exploiting Sound Masking for Audio Privacy in Smartphones"
"""

import os
import sys
import numpy as np
from pathlib import Path
from typing import Tuple, List, Optional
import argparse
import warnings
warnings.filterwarnings('ignore')

# Import audio quality metrics module
try:
    from audio_metrics import AudioMetrics
    HAVE_METRICS = True
except ImportError:
    HAVE_METRICS = False

# Audio processing dependencies
try:
    import soundfile as sf
    HAVE_SF = True
except ImportError:
    try:
        from scipy.io import wavfile
        HAVE_SF = False
    except ImportError:
        print("Warning: Need to install soundfile or scipy for audio processing")
        HAVE_SF = None

class AudioPrivacySystem:
    """Audio Privacy Protection System Main Class éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, sample_rate: int = 16000, target_snr_db: float = 0.0):
        """
        Initialize Audio Privacy Protection System
        åˆå§‹åŒ–éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ
        
        Args:
            sample_rate: Sample rate, default 16kHz (suitable for speech)
            target_snr_db: Target SNR, default 0dB (strong masking effect)
        """
        self.sr = sample_rate
        self.target_snr_db = target_snr_db
        
        # Setup input/output directories è®¾ç½®è¾“å…¥è¾“å‡ºç›®å½•
        self.dataset_dir = Path("./dataset")
        self.input_dir = self.dataset_dir / "input"
        self.output_dir = self.dataset_dir / "output"
        
        # Create directories åˆ›å»ºç›®å½•
        self.dataset_dir.mkdir(exist_ok=True)
        self.input_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize audio quality evaluator åˆå§‹åŒ–éŸ³é¢‘è´¨é‡è¯„ä¼°å™¨
        self.metrics_calc = AudioMetrics(sample_rate) if HAVE_METRICS else None
        
        # Voice feature parameters è¯­éŸ³ç‰¹å¾å‚æ•°
        self.voice_params = {
            'speech_band': (200, 4000), # Speech frequency band è¯­éŸ³é¢‘å¸¦
            'syllable_rate': (2, 5),    # Syllable rate (Hz) éŸ³èŠ‚é€Ÿç‡
        }
        
    def load_audio(self, file_path: str, force_mono: bool = True) -> Tuple[np.ndarray, int]:
        """Load audio file åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Audio file not found: {file_path}")
        
        file_ext = Path(file_path).suffix.lower()
        
        # Check if soundfile is available æ£€æŸ¥soundfileæ˜¯å¦å¯ç”¨
        try:
            import soundfile as sf
            have_soundfile = True
        except ImportError:
            have_soundfile = False
        
        # For non-WAV formats, must use soundfile å¯¹äºéWAVæ ¼å¼ï¼Œå¿…é¡»ä½¿ç”¨soundfile
        if file_ext in ['.m4a', '.mp3', '.flac', '.ogg']:
            if not have_soundfile:
                raise RuntimeError(f"File format {file_ext} requires soundfile library, install: pip install soundfile")
            try:
                data, sr = sf.read(file_path, always_2d=False)
            except Exception as e:
                raise RuntimeError(f"Cannot read audio file {file_path}: {e}")
        elif have_soundfile:
            # Try soundfile å°è¯•soundfile
            try:
                data, sr = sf.read(file_path, always_2d=False)
            except Exception:
                # If soundfile fails, try scipy (WAV only) å¦‚æœsoundfileå¤±è´¥ï¼Œå°è¯•scipyï¼ˆä»…WAVæ ¼å¼ï¼‰
                if file_ext == '.wav':
                    sr, data = wavfile.read(file_path)
                    # Normalize to float32 å½’ä¸€åŒ–åˆ°float32
                    if data.dtype == np.int16:
                        data = data.astype(np.float32) / 32768.0
                    else:
                        data = data.astype(np.float32) / np.max(1e-9 + np.abs(data))
                else:
                    raise RuntimeError(f"Cannot read audio file {file_path}, ensure soundfile library is installed")
        else:
            # Only scipy available, WAV format only åªæœ‰scipyå¯ç”¨ï¼Œä»…æ”¯æŒWAVæ ¼å¼
            if file_ext != '.wav':
                raise RuntimeError(f"File format {file_ext} requires soundfile library, install: pip install soundfile")
            
            sr, data = wavfile.read(file_path)
            # Normalize to float32 å½’ä¸€åŒ–åˆ°float32
            if data.dtype == np.int16:
                data = data.astype(np.float32) / 32768.0
            else:
                data = data.astype(np.float32) / np.max(1e-9 + np.abs(data))
        
        # Convert to mono è½¬æ¢ä¸ºå•å£°é“
        if data.ndim == 2:
            data = np.mean(data, axis=1)
        
        # Resample if needed é‡é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sr != self.sr:
            data = self._resample(data, sr, self.sr)
            sr = self.sr
            
        return data.astype(np.float32), sr
    
    def save_audio(self, file_path: str, data: np.ndarray, sr: int = None):
        """Save audio file ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        if sr is None:
            sr = self.sr
            
        data = np.asarray(data, dtype=np.float32)
        data = np.clip(data, -1.0, 1.0)
        
        # Try soundfile first ä¼˜å…ˆå°è¯•soundfile
        try:
            import soundfile as sf
            sf.write(file_path, data, sr, subtype="PCM_16")
        except ImportError:
            # Fallback to scipy å›é€€åˆ°scipy
            from scipy.io.wavfile import write as wav_write
            wav_write(file_path, sr, (data * 32767).astype(np.int16))
    
    def _resample(self, data: np.ndarray, old_sr: int, new_sr: int) -> np.ndarray:
        """Simple resampling (linear interpolation) ç®€å•é‡é‡‡æ ·ï¼ˆçº¿æ€§æ’å€¼ï¼‰"""
        if old_sr == new_sr:
            return data
            
        ratio = new_sr / old_sr
        new_len = int(len(data) * ratio)
        x_old = np.linspace(0, 1, num=len(data), endpoint=False)
        x_new = np.linspace(0, 1, num=new_len, endpoint=False)
        return np.interp(x_new, x_old, data).astype(np.float32)
    
    def generate_voice_like_mask(self, length: int, sr: int = None, mask_type: str = "voice_like") -> np.ndarray:
        """
        Generate masking noise
        ç”Ÿæˆæ©è”½å™ªå£°
        
        Args:
            length: Signal length
            sr: Sample rate
            mask_type: Type of masking noise ("voice_like", "multi_tone")
        """
        if sr is None:
            sr = self.sr
            
        if mask_type == "voice_like":
            return self._generate_voice_like_noise(length, sr)
        elif mask_type == "multi_tone":
            return self._generate_multi_tone_mask(length, sr)
        else:
            return self._generate_voice_like_noise(length, sr)
    
    def _generate_voice_like_noise(self, length: int, sr: int) -> np.ndarray:
        """Original voice-like masking noise åŸå§‹çš„ç±»è¯­éŸ³æ©è”½å™ªå£°"""
        # 1. Generate white noise ç”Ÿæˆç™½å™ªå£°
        white_noise = np.random.randn(length).astype(np.float32)
        
        # 2. Bandpass filter to speech frequency band å¸¦é€šæ»¤æ³¢åˆ°è¯­éŸ³é¢‘å¸¦
        filtered_noise = self._bandpass_filter(white_noise, sr)
        
        # 3. Add syllable modulation (simulate speech energy changes) æ·»åŠ éŸ³èŠ‚å¼è°ƒåˆ¶
        syllable_modulation = self._generate_syllable_modulation(length, sr)
        
        # 4. Combine to generate voice-like noise ç»„åˆç”Ÿæˆç±»è¯­éŸ³å™ªå£°
        voice_like = filtered_noise * syllable_modulation
        
        # 5. Normalize å½’ä¸€åŒ–
        voice_like = voice_like / (np.max(np.abs(voice_like)) + 1e-9)
        
        return voice_like.astype(np.float32)
    
    
    def _generate_multi_tone_mask(self, length: int, sr: int) -> np.ndarray:
        """Multi-tone masking with speech-like characteristics å¤šéŸ³è°ƒæ©è”½"""
        t = np.linspace(0, length / sr, length, endpoint=False)
        mask = np.zeros(length, dtype=np.float32)
        
        # Generate multiple tones in speech frequency range åœ¨è¯­éŸ³é¢‘æ®µç”Ÿæˆå¤šä¸ªéŸ³è°ƒ
        speech_tones = [300, 500, 800, 1200, 1800, 2500, 3200]  # Common speech frequencies
        
        for i, freq in enumerate(speech_tones):
            # Add slight frequency modulation æ·»åŠ è½»å¾®é¢‘ç‡è°ƒåˆ¶
            fm_freq = 0.5 + i * 0.2
            freq_mod = freq * (1 + 0.1 * np.sin(2 * np.pi * fm_freq * t))
            
            # Generate tone with amplitude modulation ç”Ÿæˆå¸¦å¹…åº¦è°ƒåˆ¶çš„éŸ³è°ƒ
            amplitude = 0.8 + 0.4 * np.sin(2 * np.pi * (0.3 + i * 0.1) * t)
            phase = 2 * np.pi * freq_mod * t + np.random.uniform(0, 2*np.pi)
            
            tone = amplitude * np.sin(phase)
            mask += tone * 0.15
        
        # Add some filtered noise for texture æ·»åŠ ä¸€äº›æ»¤æ³¢å™ªå£°å¢åŠ çº¹ç†
        noise = np.random.randn(length).astype(np.float32)
        filtered_noise = self._bandpass_filter(noise, sr)
        mask += filtered_noise * 0.3
        
        # Normalize å½’ä¸€åŒ–
        mask = mask / (np.max(np.abs(mask)) + 1e-9)
        
        return mask.astype(np.float32)
    
    
    def _bandpass_filter_custom(self, signal: np.ndarray, sr: int, low_freq: float, high_freq: float) -> np.ndarray:
        """Custom bandpass filter with specific frequency range è‡ªå®šä¹‰å¸¦é€šæ»¤æ³¢å™¨"""
        numtaps = 257
        nyq = sr / 2.0
        f1 = low_freq / nyq
        f2 = high_freq / nyq
        
        # Windowed sinc bandpass filter çª—å£åŒ–sincå¸¦é€šæ»¤æ³¢å™¨
        n = np.arange(numtaps) - (numtaps - 1) / 2.0
        
        def sinc(x):
            return np.sinc(x / np.pi)
            
        h = (2 * f2 * sinc(2 * np.pi * f2 * n) - 2 * f1 * sinc(2 * np.pi * f1 * n))
        
        # Hann window Hannçª—
        window = 0.5 * (1 - np.cos(2 * np.pi * np.arange(numtaps) / (numtaps - 1)))
        h = h * window
        
        # Normalize å½’ä¸€åŒ–
        h = h / np.sum(h)
        
        # Apply filter åº”ç”¨æ»¤æ³¢å™¨
        filtered = np.convolve(signal, h, mode='same')
        return filtered.astype(np.float32)
    
    def _bandpass_filter(self, signal: np.ndarray, sr: int) -> np.ndarray:
        """Simple bandpass filter (windowed sinc) ç®€å•çš„å¸¦é€šæ»¤æ³¢å™¨ï¼ˆçª—å£åŒ–sincï¼‰"""
        low_freq, high_freq = self.voice_params['speech_band']
        
        # Design FIR filter è®¾è®¡FIRæ»¤æ³¢å™¨
        numtaps = 513
        nyq = sr / 2.0
        f1 = low_freq / nyq
        f2 = high_freq / nyq
        
        # Windowed sinc bandpass filter çª—å£åŒ–sincå¸¦é€šæ»¤æ³¢å™¨
        n = np.arange(numtaps) - (numtaps - 1) / 2.0
        
        def sinc(x):
            return np.sinc(x / np.pi)
            
        h = (2 * f2 * sinc(2 * np.pi * f2 * n) - 2 * f1 * sinc(2 * np.pi * f1 * n))
        
        # Hann window Hannçª—
        window = 0.5 * (1 - np.cos(2 * np.pi * np.arange(numtaps) / (numtaps - 1)))
        h = h * window
        
        # Normalize å½’ä¸€åŒ–
        h = h / np.sum(h)
        
        # Apply filter åº”ç”¨æ»¤æ³¢å™¨
        filtered = np.convolve(signal, h, mode='same')
        return filtered.astype(np.float32)
    
    def _generate_syllable_modulation(self, length: int, sr: int) -> np.ndarray:
        """Generate syllable modulation signal ç”ŸæˆéŸ³èŠ‚å¼è°ƒåˆ¶ä¿¡å·"""
        # Random syllable rate éšæœºéŸ³èŠ‚é€Ÿç‡
        syllable_rate = np.random.uniform(*self.voice_params['syllable_rate'])
        
        # Generate random envelope ç”ŸæˆéšæœºåŒ…ç»œ
        env_length = max(1, length // 400)  # Coarse envelope ç²—ç²’åº¦åŒ…ç»œ
        envelope = np.abs(np.random.randn(env_length)).astype(np.float32)
        
        # Upsample to signal length ä¸Šé‡‡æ ·åˆ°ä¿¡å·é•¿åº¦
        t_env = np.linspace(0, env_length - 1, num=length)
        envelope_up = np.interp(t_env, np.arange(env_length), envelope)
        
        # Smooth envelope (simulate syllable boundaries) å¹³æ»‘åŒ…ç»œï¼ˆæ¨¡æ‹ŸéŸ³èŠ‚è¾¹ç•Œï¼‰
        smooth_kernel = np.ones(51, dtype=np.float32) / 51.0
        envelope_smooth = np.convolve(envelope_up, smooth_kernel, mode='same')
        envelope_smooth = envelope_smooth / (np.max(np.abs(envelope_smooth)) + 1e-9)
        
        # Add syllable modulation æ·»åŠ éŸ³èŠ‚å¼è°ƒåˆ¶
        t = np.linspace(0, length / sr, length, endpoint=False)
        syllable_mod = 0.3 + 0.7 * (0.5 + 0.5 * np.sin(2 * np.pi * syllable_rate * t))
        
        return envelope_smooth * syllable_mod
    
    def mix_signals(self, clean: np.ndarray, mask: np.ndarray, target_snr_db: float = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        Mix clean signal and masking signal at specified SNR
        å°†å¹²å‡€ä¿¡å·å’Œæ©è”½ä¿¡å·æŒ‰æŒ‡å®šä¿¡å™ªæ¯”æ··åˆ
        
        Args:
            clean: Clean speech signal
            mask: Masking noise signal
            target_snr_db: Target SNR (dB)
            
        Returns:
            mixed: Mixed signal
            scaled_mask: Scaled masking signal
        """
        if target_snr_db is None:
            target_snr_db = self.target_snr_db
            
        # Calculate RMS è®¡ç®—RMS
        clean_rms = np.sqrt(np.mean(clean ** 2) + 1e-12)
        mask_rms = np.sqrt(np.mean(mask ** 2) + 1e-12)
        
        if mask_rms < 1e-12:
            return clean.copy(), mask.copy()
        
        # Calculate required masking signal amplitude è®¡ç®—æ‰€éœ€çš„æ©è”½ä¿¡å·å¹…åº¦
        desired_mask_rms = clean_rms / (10.0 ** (target_snr_db / 20.0))
        scale_factor = desired_mask_rms / mask_rms
        
        # Scale masking signal ç¼©æ”¾æ©è”½ä¿¡å·
        scaled_mask = mask * scale_factor
        
        # Mix signals æ··åˆä¿¡å·
        mixed = clean + scaled_mask
        
        return mixed, scaled_mask
    
    def lms_recovery(self, mixed: np.ndarray, mask_ref: np.ndarray, 
                     mu: float = 0.01, filter_order: int = 128) -> Tuple[np.ndarray, np.ndarray]:
        """
        LMS adaptive filter for authorized recovery
        LMSè‡ªé€‚åº”æ»¤æ³¢å™¨è¿›è¡Œæˆæƒæ¢å¤
        
        Args:
            mixed: Observed signal (clean + mask)
            mask_ref: Reference masking signal (known to authorized party)
            mu: Learning rate
            filter_order: Filter order
            
        Returns:
            recovered: Recovered clean signal
            filter_taps: Filter coefficients
        """
        n = len(mixed)
        w = np.zeros(filter_order, dtype=np.float32)
        x_buffer = np.zeros(filter_order, dtype=np.float32)
        recovered = np.zeros(n, dtype=np.float32)
        
        for i in range(n):
            # Update input buffer æ›´æ–°è¾“å…¥ç¼“å†²åŒº
            x_buffer[1:] = x_buffer[:-1]
            x_buffer[0] = mask_ref[i] if i < len(mask_ref) else 0.0
            
            # Calculate filter output è®¡ç®—æ»¤æ³¢å™¨è¾“å‡º
            y = np.dot(w, x_buffer)
            
            # Calculate error signal (should be clean speech estimate) è®¡ç®—è¯¯å·®ä¿¡å·
            error = mixed[i] - y
            recovered[i] = error
            
            # LMS update LMSæ›´æ–°
            w += 2 * mu * error * x_buffer
        
        return recovered, w
    
    def calculate_snr(self, signal: np.ndarray, noise: np.ndarray) -> float:
        """Calculate Signal-to-Noise Ratio (dB) è®¡ç®—ä¿¡å™ªæ¯”ï¼ˆdBï¼‰"""
        signal_power = np.mean(signal ** 2) + 1e-12
        noise_power = np.mean(noise ** 2) + 1e-12
        
        if noise_power < 1e-12:
            return float('inf')  # No noise case æ— å™ªå£°æƒ…å†µ
        
        snr = 10.0 * np.log10(signal_power / noise_power)
        
        # Handle NaN and infinity å¤„ç†NaNå’Œæ— ç©·å¤§å€¼
        if np.isnan(snr) or np.isinf(snr):
            return 0.0
            
        return snr
    
    def process_audio_pair(self, clean_path: str, output_prefix: str = "", mask_type: str = "voice_like") -> dict:
        """
        Process audio pair: clean speech -> masking -> mixing -> recovery
        å¤„ç†éŸ³é¢‘å¯¹ï¼šå¹²å‡€è¯­éŸ³ -> æ©è”½ -> æ··åˆ -> æ¢å¤
        
        Args:
            clean_path: Clean speech file path
            output_prefix: Output file prefix
            
        Returns:
            Processing results dictionary
        """
        # 1. Load clean speech åŠ è½½å¹²å‡€è¯­éŸ³
        clean, _ = self.load_audio(clean_path)
        print(f"Loading clean speech: {clean_path}, length: {len(clean)/self.sr:.2f}s")
        
        # 2. Generate masking noise ç”Ÿæˆæ©è”½å™ªå£°
        mask = self.generate_voice_like_mask(len(clean), mask_type=mask_type)
        print(f"Generating {mask_type} masking noise")
        
        # 3. Mix signals æ··åˆä¿¡å·
        mixed, scaled_mask = self.mix_signals(clean, mask)
        print(f"Mixing signals, target SNR: {self.target_snr_db:.1f}dB")
        
        # 4. Authorized recovery æˆæƒæ¢å¤
        recovered, filter_taps = self.lms_recovery(mixed, scaled_mask)
        print("Executing LMS authorized recovery")
        
        # 5. Calculate performance metrics è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        snr_input = self.calculate_snr(clean, scaled_mask)
        snr_after = self.calculate_snr(clean, recovered - clean)
        improvement = snr_after - snr_input
        
        print(f"Input SNR: {snr_input:.2f}dB")
        print(f"Recovery SNR: {snr_after:.2f}dB")
        print(f"SNR improvement: {improvement:.2f}dB")
        
        # 6. Detailed quality assessment (if available) è¯¦ç»†è´¨é‡è¯„ä¼°
        if self.metrics_calc:
            print("\nğŸ“Š Detailed Quality Assessment:")
            mixed_metrics = self.metrics_calc.calculate_all_metrics(clean, mixed)
            recovery_metrics = self.metrics_calc.evaluate_recovery_quality(clean, recovered)
            
            print(f"Mixed signal quality:")
            print(f"  - SNR: {mixed_metrics['snr_db']:.2f} dB")
            print(f"  - STOI: {mixed_metrics['stoi']:.3f}")
            
            print(f"Recovery signal quality:")
            print(f"  - SNR: {recovery_metrics['snr_db']:.2f} dB")
            print(f"  - STOI: {recovery_metrics['stoi']:.3f}")
            print(f"  - Signal preservation: {recovery_metrics['signal_preservation']:.3f}")
        
        # 7. Save files ä¿å­˜æ–‡ä»¶
        if not output_prefix:
            output_prefix = Path(clean_path).stem
            
        # Save to new output directory ä¿å­˜åˆ°æ–°çš„è¾“å‡ºç›®å½•
        clean_out = self.output_dir / f"{output_prefix}_clean.wav"
        mask_out = self.output_dir / f"{output_prefix}_mask_{mask_type}.wav"
        mixed_out = self.output_dir / f"{output_prefix}_mixed_{mask_type}.wav"
        recovered_out = self.output_dir / f"{output_prefix}_recovered_{mask_type}.wav"
        
        self.save_audio(clean_out, clean)
        self.save_audio(mask_out, scaled_mask)
        self.save_audio(mixed_out, mixed)
        self.save_audio(recovered_out, recovered)
        
        # 8. Return results è¿”å›ç»“æœ
        results = {
            'input_file': clean_path,
            'output_files': {
                'clean': str(clean_out),
                'mask': str(mask_out),
                'mixed': str(mixed_out),
                'recovered': str(recovered_out)
            },
            'metrics': {
                'input_snr_db': snr_input,
                'output_snr_db': snr_after,
                'improvement_db': improvement,
                'signal_length_sec': len(clean) / self.sr
            },
            'parameters': {
                'sample_rate': self.sr,
                'target_snr_db': self.target_snr_db,
                'filter_order': 128,
                'learning_rate': 0.01
            }
        }
        
        return results
    
    def batch_process(self, clean_files: List[str], output_prefixes: List[str] = None) -> List[dict]:
        """Batch process multiple audio files æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶"""
        if output_prefixes is None:
            output_prefixes = [Path(f).stem for f in clean_files]
            
        results = []
        for clean_file, prefix in zip(clean_files, output_prefixes):
            try:
                result = self.process_audio_pair(clean_file, prefix)
                results.append(result)
                print(f"âœ“ Processing completed: {prefix}")
            except Exception as e:
                print(f"âœ— Processing failed: {prefix}, error: {e}")
                results.append(None)
                
        return results
    


def main():
    """Main function - Audio Privacy Protection System ä¸»å‡½æ•° - éŸ³é¢‘éšç§ä¿æŠ¤ç³»ç»Ÿ"""
    parser = argparse.ArgumentParser(description='Audio Privacy Protection System')
    parser.add_argument('--input', '-i', type=str, help='Input audio file path')
    parser.add_argument('--batch', '-b', type=str, help='Batch processing directory path')
    parser.add_argument('--snr', type=float, default=0.0, help='Target SNR (dB)')
    parser.add_argument('--sample-rate', type=int, default=16000, help='Sample rate (Hz)')
    parser.add_argument('--mask-type', type=str, default='voice_like', 
                       choices=['voice_like', 'multi_tone'],
                       help='Type of masking noise')
    
    args = parser.parse_args()
    
    print("=== Audio Privacy Protection System ===")
    print("Based on sound masking techniques for smartphone audio privacy")
    print()
    
    # Initialize system åˆå§‹åŒ–ç³»ç»Ÿ
    system = AudioPrivacySystem(sample_rate=args.sample_rate, target_snr_db=args.snr)
    
    if args.input:
        # Process single file å¤„ç†å•ä¸ªæ–‡ä»¶
        print(f"Processing single file: {args.input}")
        result = system.process_audio_pair(args.input, mask_type=args.mask_type)
        print(f"\nProcessing results:")
        print(f"- Input SNR: {result['metrics']['input_snr_db']:.2f}dB")
        print(f"- Recovery SNR: {result['metrics']['output_snr_db']:.2f}dB")
        print(f"- SNR improvement: {result['metrics']['improvement_db']:.2f}dB")
        print(f"\nOutput files saved to: {system.output_dir}")
        
    elif args.batch:
        # Batch processing æ‰¹é‡å¤„ç†
        batch_dir = Path(args.batch)
        if not batch_dir.exists():
            print(f"Error: Directory does not exist: {batch_dir}")
            return
            
        audio_files = []
        for ext in ['*.wav', '*.m4a', '*.mp3', '*.flac']:
            audio_files.extend(batch_dir.glob(ext))
        
        if not audio_files:
            print(f"Error: No audio files found in directory: {batch_dir}")
            return
            
        print(f"Batch processing {len(audio_files)} files")
        results = system.batch_process([str(f) for f in audio_files])
        
        valid_results = [r for r in results if r is not None]
        if valid_results:
            avg_improvement = np.mean([r['metrics']['improvement_db'] for r in valid_results])
            print(f"\nBatch processing results:")
            print(f"- Successfully processed: {len(valid_results)}/{len(results)} files")
            print(f"- Average SNR improvement: {avg_improvement:.2f}dB")
        
    else:
        # Default demo mode é»˜è®¤æ¼”ç¤ºæ¨¡å¼
        input_files = []
        for ext in ['*.wav', '*.m4a', '*.mp3', '*.flac']:
            input_files.extend(system.input_dir.glob(ext))
        
        if input_files:
            print(f"Found {len(input_files)} input audio files")
            print("Processing first file for demo...")
            
            first_file = input_files[0]
            result = system.process_audio_pair(str(first_file), mask_type=args.mask_type)
            print(f"\nProcessing results:")
            print(f"- File: {first_file.name}")
            print(f"- Input SNR: {result['metrics']['input_snr_db']:.2f}dB")
            print(f"- Recovery SNR: {result['metrics']['output_snr_db']:.2f}dB")
            print(f"- SNR improvement: {result['metrics']['improvement_db']:.2f}dB")
            print(f"\nOutput files saved to: {system.output_dir}")
            
            if len(input_files) > 1:
                print(f"\nğŸ’¡ Tip: {len(input_files)-1} more files to process")
                print("Use --batch dataset/input for batch processing")
        else:
            print("No input audio files found.")
            print("Please place audio files in dataset/input/ directory, or use:")
            print("  python audio_privacy_system.py --input <file_path>")
            print("  python audio_privacy_system.py --batch <directory_path>")
    
    print("\n=== System Description ===")
    print("1. Clean speech: Original speech signal")
    print("2. Masking noise: Voice-like noise signal")
    print("3. Mixed signal: What eavesdroppers would record (unclear)")
    print("4. Recovered signal: Clear speech recovered by authorized parties")
    print("\nCore principle: Only authorized parties know the exact masking parameters to reverse recovery")


if __name__ == "__main__":
    main()
